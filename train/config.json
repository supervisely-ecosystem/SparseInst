{
    "name": "Train SparseInst",
    "version": "2.0.0",
    "type": "app",
    "categories": [
        "neural network",
        "images",
        "instance segmentation",
        "train",
        "framework:SparseInst"
    ],
    "description": "Dashboard to configure, start and monitor SparseInst training",
    "docker_image": "supervisely/sparseinst:1.0.4",
    "instance_version": "6.14.0",
    "entrypoint": "python3 -m uvicorn src.main:train.app --app-dir ./train --host 0.0.0.0 --port 8000 --ws websockets",
    "task_location": "workspace_tasks",
    "need_gpu": true,
    "gpu": "required",
    "isolate": true,
    "icon": "https://github.com/supervisely-ecosystem/SparseInst/releases/download/v0.0.1/icon_sparseInst-train.jpg",
    "icon_cover": true,
    "poster": "https://github.com/supervisely-ecosystem/SparseInst/releases/download/v0.0.1/poster_sparseInst-train.jpg",
    "community_agent": false,
    "license": {
        "type": "MIT"
    },
    "context_menu": {
        "target": [
            "images_project"
        ],
        "context_root": "Neural Networks"
    },
    "framework": {
        "name": "SparseInst",
        "tags": [
            "Real-Time"
        ],
        "export": [
            "ONNX",
            "TensorRT"
        ],
        "conference": "CVPR 2022",
        "released": "2022",
        "description": "SparseInst presents a new object representation method (Instance Activation Maps), to adaptively highlight informative regions of objects for recognition. SparseInst achieves good trade-off between speed and accuracy (37.9 AP and 40 FPS with 608x input).",
        "github": "https://github.com/hustvl/SparseInst"
    },
    "files": {
        "models": "models/models.json",
        "inference_settings": "serve/src/inference_settings.yaml",
        "hyperparams": "train/src/hyperparameters.yaml"
    }
}